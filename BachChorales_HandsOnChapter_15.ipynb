{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BachChorales_HandsOnChapter-15.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar-abhishek/handson-ml2/blob/master/BachChorales_HandsOnChapter_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pugAaqoQ2miR",
        "colab_type": "code",
        "outputId": "489e7913-d325-489a-94e2-707d3b94fb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence)-1:\n",
        "     break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return array(X), array(y)\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10 20 30]\n",
            " [20 30 40]\n",
            " [30 40 50]\n",
            " [40 50 60]\n",
            " [50 60 70]\n",
            " [60 70 80]]\n",
            "[40 50 60 70 80 90]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WVx7XFSRNCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features))) model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "                                                                                   \n",
        "print(yhat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Si9sjBRGoE",
        "colab_type": "code",
        "outputId": "7ff3921b-a9a0-4c9b-b15b-11d29fbd5cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# multivariate output stacked lstm example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequences)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the dataset\n",
        "    if end_ix > len(sequences)-1:\n",
        "     break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "print(dataset)\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "print(X)\n",
        "print(y)\n",
        "print(type(X))\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "print(n_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 10  15  25]\n",
            " [ 20  25  45]\n",
            " [ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]\n",
            " [ 80  85 165]\n",
            " [ 90  95 185]]\n",
            "[[[10 15 25]\n",
            "  [20 25 45]\n",
            "  [30 35 65]]]\n",
            "[[40 45 85]]\n",
            "<class 'numpy.ndarray'>\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Azwr1ubOCLh",
        "colab_type": "code",
        "outputId": "459612d6-d934-412c-ef64-0a405a0a3f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(100, activation='relu')) \n",
        "model.add(Dense(n_features)) \n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7935424e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nndS5_BtODUw",
        "colab_type": "code",
        "outputId": "b707b692-945e-433d-d5eb-2db74ef0de79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# demonstrate prediction\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[197.93314 223.3317  407.88092]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fmXPTqmLxe9",
        "colab_type": "text"
      },
      "source": [
        "**Q10[part-1]. Download the Bach chorales dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note’s index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. **bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k9Phc0e7EFM",
        "colab_type": "code",
        "outputId": "2c1678f5-f88f-405f-a457-4754dca50803",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ff5fdb8-4d35-423d-85e3-767f2c90a410\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0ff5fdb8-4d35-423d-85e3-767f2c90a410\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving chorale_000.csv to chorale_000 (1).csv\n",
            "Saving chorale_001.csv to chorale_001.csv\n",
            "Saving chorale_002.csv to chorale_002.csv\n",
            "Saving chorale_003.csv to chorale_003.csv\n",
            "Saving chorale_004.csv to chorale_004.csv\n",
            "Saving chorale_005.csv to chorale_005.csv\n",
            "Saving chorale_006.csv to chorale_006.csv\n",
            "Saving chorale_007.csv to chorale_007.csv\n",
            "Saving chorale_008.csv to chorale_008.csv\n",
            "Saving chorale_009.csv to chorale_009.csv\n",
            "Saving chorale_010.csv to chorale_010.csv\n",
            "Saving chorale_011.csv to chorale_011.csv\n",
            "Saving chorale_012.csv to chorale_012.csv\n",
            "Saving chorale_013.csv to chorale_013.csv\n",
            "Saving chorale_014.csv to chorale_014.csv\n",
            "Saving chorale_015.csv to chorale_015.csv\n",
            "Saving chorale_016.csv to chorale_016.csv\n",
            "Saving chorale_017.csv to chorale_017.csv\n",
            "Saving chorale_018.csv to chorale_018.csv\n",
            "Saving chorale_019.csv to chorale_019.csv\n",
            "Saving chorale_020.csv to chorale_020.csv\n",
            "Saving chorale_021.csv to chorale_021.csv\n",
            "Saving chorale_022.csv to chorale_022.csv\n",
            "Saving chorale_023.csv to chorale_023.csv\n",
            "Saving chorale_024.csv to chorale_024.csv\n",
            "Saving chorale_025.csv to chorale_025.csv\n",
            "Saving chorale_026.csv to chorale_026.csv\n",
            "Saving chorale_027.csv to chorale_027.csv\n",
            "Saving chorale_028.csv to chorale_028.csv\n",
            "Saving chorale_029.csv to chorale_029.csv\n",
            "Saving chorale_030.csv to chorale_030.csv\n",
            "Saving chorale_031.csv to chorale_031.csv\n",
            "Saving chorale_032.csv to chorale_032.csv\n",
            "Saving chorale_033.csv to chorale_033.csv\n",
            "Saving chorale_034.csv to chorale_034.csv\n",
            "Saving chorale_035.csv to chorale_035.csv\n",
            "Saving chorale_036.csv to chorale_036.csv\n",
            "Saving chorale_037.csv to chorale_037.csv\n",
            "Saving chorale_038.csv to chorale_038.csv\n",
            "Saving chorale_039.csv to chorale_039.csv\n",
            "Saving chorale_040.csv to chorale_040.csv\n",
            "Saving chorale_041.csv to chorale_041.csv\n",
            "Saving chorale_042.csv to chorale_042.csv\n",
            "Saving chorale_043.csv to chorale_043.csv\n",
            "Saving chorale_044.csv to chorale_044.csv\n",
            "Saving chorale_045.csv to chorale_045.csv\n",
            "Saving chorale_046.csv to chorale_046.csv\n",
            "Saving chorale_047.csv to chorale_047.csv\n",
            "Saving chorale_048.csv to chorale_048.csv\n",
            "Saving chorale_049.csv to chorale_049.csv\n",
            "Saving chorale_050.csv to chorale_050.csv\n",
            "Saving chorale_051.csv to chorale_051.csv\n",
            "Saving chorale_052.csv to chorale_052.csv\n",
            "Saving chorale_053.csv to chorale_053.csv\n",
            "Saving chorale_054.csv to chorale_054.csv\n",
            "Saving chorale_055.csv to chorale_055.csv\n",
            "Saving chorale_056.csv to chorale_056.csv\n",
            "Saving chorale_057.csv to chorale_057.csv\n",
            "Saving chorale_058.csv to chorale_058.csv\n",
            "Saving chorale_059.csv to chorale_059.csv\n",
            "Saving chorale_060.csv to chorale_060.csv\n",
            "Saving chorale_061.csv to chorale_061.csv\n",
            "Saving chorale_062.csv to chorale_062.csv\n",
            "Saving chorale_063.csv to chorale_063.csv\n",
            "Saving chorale_064.csv to chorale_064.csv\n",
            "Saving chorale_065.csv to chorale_065.csv\n",
            "Saving chorale_066.csv to chorale_066.csv\n",
            "Saving chorale_067.csv to chorale_067.csv\n",
            "Saving chorale_068.csv to chorale_068.csv\n",
            "Saving chorale_069.csv to chorale_069.csv\n",
            "Saving chorale_070.csv to chorale_070.csv\n",
            "Saving chorale_071.csv to chorale_071.csv\n",
            "Saving chorale_072.csv to chorale_072.csv\n",
            "Saving chorale_073.csv to chorale_073.csv\n",
            "Saving chorale_074.csv to chorale_074.csv\n",
            "Saving chorale_075.csv to chorale_075.csv\n",
            "Saving chorale_076.csv to chorale_076.csv\n",
            "Saving chorale_077.csv to chorale_077.csv\n",
            "Saving chorale_078.csv to chorale_078.csv\n",
            "Saving chorale_079.csv to chorale_079.csv\n",
            "Saving chorale_080.csv to chorale_080.csv\n",
            "Saving chorale_081.csv to chorale_081.csv\n",
            "Saving chorale_082.csv to chorale_082.csv\n",
            "Saving chorale_083.csv to chorale_083.csv\n",
            "Saving chorale_084.csv to chorale_084.csv\n",
            "Saving chorale_085.csv to chorale_085.csv\n",
            "Saving chorale_086.csv to chorale_086.csv\n",
            "Saving chorale_087.csv to chorale_087.csv\n",
            "Saving chorale_088.csv to chorale_088.csv\n",
            "Saving chorale_089.csv to chorale_089.csv\n",
            "Saving chorale_090.csv to chorale_090.csv\n",
            "Saving chorale_091.csv to chorale_091.csv\n",
            "Saving chorale_092.csv to chorale_092.csv\n",
            "Saving chorale_093.csv to chorale_093.csv\n",
            "Saving chorale_094.csv to chorale_094.csv\n",
            "Saving chorale_095.csv to chorale_095.csv\n",
            "Saving chorale_096.csv to chorale_096.csv\n",
            "Saving chorale_097.csv to chorale_097.csv\n",
            "Saving chorale_098.csv to chorale_098.csv\n",
            "Saving chorale_099.csv to chorale_099.csv\n",
            "Saving chorale_100.csv to chorale_100.csv\n",
            "Saving chorale_101.csv to chorale_101.csv\n",
            "Saving chorale_102.csv to chorale_102.csv\n",
            "Saving chorale_103.csv to chorale_103.csv\n",
            "Saving chorale_104.csv to chorale_104.csv\n",
            "Saving chorale_105.csv to chorale_105.csv\n",
            "Saving chorale_106.csv to chorale_106.csv\n",
            "Saving chorale_107.csv to chorale_107.csv\n",
            "Saving chorale_108.csv to chorale_108.csv\n",
            "Saving chorale_109.csv to chorale_109.csv\n",
            "Saving chorale_110.csv to chorale_110.csv\n",
            "Saving chorale_111.csv to chorale_111.csv\n",
            "Saving chorale_112.csv to chorale_112.csv\n",
            "Saving chorale_113.csv to chorale_113.csv\n",
            "Saving chorale_114.csv to chorale_114.csv\n",
            "Saving chorale_115.csv to chorale_115.csv\n",
            "Saving chorale_116.csv to chorale_116.csv\n",
            "Saving chorale_117.csv to chorale_117.csv\n",
            "Saving chorale_118.csv to chorale_118.csv\n",
            "Saving chorale_119.csv to chorale_119.csv\n",
            "Saving chorale_120.csv to chorale_120.csv\n",
            "Saving chorale_121.csv to chorale_121.csv\n",
            "Saving chorale_122.csv to chorale_122.csv\n",
            "Saving chorale_123.csv to chorale_123.csv\n",
            "Saving chorale_124.csv to chorale_124.csv\n",
            "Saving chorale_125.csv to chorale_125.csv\n",
            "Saving chorale_126.csv to chorale_126.csv\n",
            "Saving chorale_127.csv to chorale_127.csv\n",
            "Saving chorale_128.csv to chorale_128.csv\n",
            "Saving chorale_129.csv to chorale_129.csv\n",
            "Saving chorale_130.csv to chorale_130.csv\n",
            "Saving chorale_131.csv to chorale_131.csv\n",
            "Saving chorale_132.csv to chorale_132.csv\n",
            "Saving chorale_133.csv to chorale_133.csv\n",
            "Saving chorale_134.csv to chorale_134.csv\n",
            "Saving chorale_135.csv to chorale_135.csv\n",
            "Saving chorale_136.csv to chorale_136.csv\n",
            "Saving chorale_137.csv to chorale_137.csv\n",
            "Saving chorale_138.csv to chorale_138.csv\n",
            "Saving chorale_139.csv to chorale_139.csv\n",
            "Saving chorale_140.csv to chorale_140.csv\n",
            "Saving chorale_141.csv to chorale_141.csv\n",
            "Saving chorale_142.csv to chorale_142.csv\n",
            "Saving chorale_143.csv to chorale_143.csv\n",
            "Saving chorale_144.csv to chorale_144.csv\n",
            "Saving chorale_145.csv to chorale_145.csv\n",
            "Saving chorale_146.csv to chorale_146.csv\n",
            "Saving chorale_147.csv to chorale_147.csv\n",
            "Saving chorale_148.csv to chorale_148.csv\n",
            "Saving chorale_149.csv to chorale_149.csv\n",
            "Saving chorale_150.csv to chorale_150.csv\n",
            "Saving chorale_151.csv to chorale_151.csv\n",
            "Saving chorale_152.csv to chorale_152.csv\n",
            "Saving chorale_153.csv to chorale_153.csv\n",
            "Saving chorale_154.csv to chorale_154.csv\n",
            "Saving chorale_155.csv to chorale_155.csv\n",
            "Saving chorale_156.csv to chorale_156.csv\n",
            "Saving chorale_157.csv to chorale_157.csv\n",
            "Saving chorale_158.csv to chorale_158.csv\n",
            "Saving chorale_159.csv to chorale_159.csv\n",
            "Saving chorale_160.csv to chorale_160.csv\n",
            "Saving chorale_161.csv to chorale_161.csv\n",
            "Saving chorale_162.csv to chorale_162.csv\n",
            "Saving chorale_163.csv to chorale_163.csv\n",
            "Saving chorale_164.csv to chorale_164.csv\n",
            "Saving chorale_165.csv to chorale_165.csv\n",
            "Saving chorale_166.csv to chorale_166.csv\n",
            "Saving chorale_167.csv to chorale_167.csv\n",
            "Saving chorale_168.csv to chorale_168.csv\n",
            "Saving chorale_169.csv to chorale_169.csv\n",
            "Saving chorale_170.csv to chorale_170.csv\n",
            "Saving chorale_171.csv to chorale_171.csv\n",
            "Saving chorale_172.csv to chorale_172.csv\n",
            "Saving chorale_173.csv to chorale_173.csv\n",
            "Saving chorale_174.csv to chorale_174.csv\n",
            "Saving chorale_175.csv to chorale_175.csv\n",
            "Saving chorale_176.csv to chorale_176.csv\n",
            "Saving chorale_177.csv to chorale_177.csv\n",
            "Saving chorale_178.csv to chorale_178.csv\n",
            "Saving chorale_179.csv to chorale_179.csv\n",
            "Saving chorale_180.csv to chorale_180.csv\n",
            "Saving chorale_181.csv to chorale_181.csv\n",
            "Saving chorale_182.csv to chorale_182.csv\n",
            "Saving chorale_183.csv to chorale_183.csv\n",
            "Saving chorale_184.csv to chorale_184.csv\n",
            "Saving chorale_185.csv to chorale_185.csv\n",
            "Saving chorale_186.csv to chorale_186.csv\n",
            "Saving chorale_187.csv to chorale_187.csv\n",
            "Saving chorale_188.csv to chorale_188.csv\n",
            "Saving chorale_189.csv to chorale_189.csv\n",
            "Saving chorale_190.csv to chorale_190.csv\n",
            "Saving chorale_191.csv to chorale_191.csv\n",
            "Saving chorale_192.csv to chorale_192.csv\n",
            "Saving chorale_193.csv to chorale_193.csv\n",
            "Saving chorale_194.csv to chorale_194.csv\n",
            "Saving chorale_195.csv to chorale_195.csv\n",
            "Saving chorale_196.csv to chorale_196.csv\n",
            "Saving chorale_197.csv to chorale_197.csv\n",
            "Saving chorale_198.csv to chorale_198.csv\n",
            "Saving chorale_199.csv to chorale_199.csv\n",
            "Saving chorale_200.csv to chorale_200.csv\n",
            "Saving chorale_201.csv to chorale_201.csv\n",
            "Saving chorale_202.csv to chorale_202.csv\n",
            "Saving chorale_203.csv to chorale_203.csv\n",
            "Saving chorale_204.csv to chorale_204.csv\n",
            "Saving chorale_205.csv to chorale_205.csv\n",
            "Saving chorale_206.csv to chorale_206.csv\n",
            "Saving chorale_207.csv to chorale_207.csv\n",
            "Saving chorale_208.csv to chorale_208.csv\n",
            "Saving chorale_209.csv to chorale_209.csv\n",
            "Saving chorale_210.csv to chorale_210.csv\n",
            "Saving chorale_211.csv to chorale_211.csv\n",
            "Saving chorale_212.csv to chorale_212.csv\n",
            "Saving chorale_213.csv to chorale_213.csv\n",
            "Saving chorale_214.csv to chorale_214.csv\n",
            "Saving chorale_215.csv to chorale_215.csv\n",
            "Saving chorale_216.csv to chorale_216.csv\n",
            "Saving chorale_217.csv to chorale_217.csv\n",
            "Saving chorale_218.csv to chorale_218.csv\n",
            "Saving chorale_219.csv to chorale_219.csv\n",
            "Saving chorale_220.csv to chorale_220.csv\n",
            "Saving chorale_221.csv to chorale_221.csv\n",
            "Saving chorale_222.csv to chorale_222.csv\n",
            "Saving chorale_223.csv to chorale_223.csv\n",
            "Saving chorale_224.csv to chorale_224.csv\n",
            "Saving chorale_225.csv to chorale_225.csv\n",
            "Saving chorale_226.csv to chorale_226.csv\n",
            "Saving chorale_227.csv to chorale_227.csv\n",
            "Saving chorale_228.csv to chorale_228.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpnbslo39PR_",
        "colab_type": "code",
        "outputId": "512da029-18f7-4b05-9d48-a60631074865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "X_train_000 = pd.read_csv('chorale_000.csv')\n",
        "print(X_train_000.head(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   note0  note1  note2  note3\n",
            "0     74     70     65     58\n",
            "1     74     70     65     58\n",
            "2     74     70     65     58\n",
            "3     74     70     65     58\n",
            "4     75     70     58     55\n",
            "5     75     70     58     55\n",
            "6     75     70     60     55\n",
            "7     75     70     60     55\n",
            "8     77     69     62     50\n",
            "9     77     69     62     50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLZKNOoI9fBd",
        "colab_type": "code",
        "outputId": "fd6d9692-e64d-4054-979a-89651b40be83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "X_train_000 = X_train_000.to_numpy()\n",
        "dataX=[]\n",
        "dataY=[]\n",
        "for row in range(len(X_train_000)-1):\n",
        "    dataX.append(X_train_000[row])\n",
        "    dataY.append(X_train_000[row+1])\n",
        "print(dataX[0:5])\n",
        "print(dataY[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-9fe9d5a58fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_000\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train_000\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdataX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ziuhgmgj9p7s",
        "colab_type": "code",
        "outputId": "0725cd5c-3f4e-4e42-9a35-565fcaad5e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\"\"\"X = np.reshape(dataX, (len(dataX), 1, 4))\n",
        "X_train, X_test, y_train,  y_test = train_test_split(X, dataY, test_size=0.33, random_state=42)\n",
        "print(X_train[0:5])\n",
        "print(y_train[0:5])\n",
        "\"\"\"\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "i=0\n",
        "X=[]\n",
        "y=[]\n",
        "while i+2<len(dataX):\n",
        "  #multi-input\n",
        "  X.append(np.array([dataX[i], dataX[i+1], dataX[i+2]]).tolist())\n",
        "  y.append(dataX[i+1])\n",
        "  i += 1\n",
        "  \n",
        "X=np.asarray(X)\n",
        "y=np.asarray(y)\n",
        "print(X[0:2])\n",
        "print(y[0:2])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[74 70 65 58]\n",
            "  [74 70 65 58]\n",
            "  [74 70 65 58]]\n",
            "\n",
            " [[74 70 65 58]\n",
            "  [74 70 65 58]\n",
            "  [74 70 65 58]]]\n",
            "[[74 70 65 58]\n",
            " [74 70 65 58]]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMqQLUC19ryw",
        "colab_type": "code",
        "outputId": "67822dd3-b261-4645-d135-183a7f6ec3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "print(n_features)\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(100, activation='relu')) \n",
        "model.add(Dense(n_features)) \n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=100, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7934016da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flGBYEy0-gdD",
        "colab_type": "code",
        "outputId": "a2e3d36a-c776-4abd-c9d5-dcb79425552a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# demonstrate prediction\n",
        "print(X_train_000.head(10))\n",
        "x_input = X[5]\n",
        "print(x_input)\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   note0  note1  note2  note3\n",
            "0     74     70     65     58\n",
            "1     74     70     65     58\n",
            "2     74     70     65     58\n",
            "3     74     70     65     58\n",
            "4     75     70     58     55\n",
            "5     75     70     58     55\n",
            "6     75     70     60     55\n",
            "7     75     70     60     55\n",
            "8     77     69     62     50\n",
            "9     77     69     62     50\n",
            "[[75 70 58 55]\n",
            " [75 70 60 55]\n",
            " [75 70 60 55]]\n",
            "[[76.12141  68.754715 59.21863  56.11482 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpvggFUajEDg",
        "colab_type": "text"
      },
      "source": [
        "**Q10[part-2] Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out Google’s Coconet model, which was used for a nice Google doodle about Bach.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W78Jp-nAjKE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}