{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion-cause-extraction-dl.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar-abhishek/handson-ml2/blob/master/emotion_cause_extraction_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_JuRbQG0Exl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6f49d41b-d670-4370-b463-33de3b8d8220"
      },
      "source": [
        "# https://github.com/nazem-Aldroubi/emotion-cause-extraction-dl-final-proj/blob/master/preprocess.py\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-588355b5-706d-4be1-8b4f-b847c6b4acf6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-588355b5-706d-4be1-8b4f-b847c6b4acf6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.txt to data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tE5KlOy23t-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb8bd8ea-bebc-4e30-b80a-5195bfa35ff4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#!pip install tensorflow==2.0.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ug2boiX0Xtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "71d15814-0fec-4ea5-ef0c-62d8d817b4c0"
      },
      "source": [
        "run model.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUMBER OF TRAIN CLAUSES:  (30, 26)\n",
            "NUMBER OF EXTRACTED TRAIN EMOTION CLAUSES:  (19, 26)\n",
            "NUMBER OF EXTRACTED TRAIN CAUSE CLAUSES:  (18, 26)\n",
            "NUMBER OF TEST CLAUSES:  (30, 26)\n",
            "NUMBER OF EXTRACTED TEST EMOTION CLAUSES:  (17, 26)\n",
            "NUMBER OF EXTRACTED TEST CAUSE CLAUSES:  (17, 26)\n",
            "FILTER MODEL EPOCH  0\n",
            "FILTER MODEL EPOCH  1\n",
            "FILTER MODEL EPOCH  2\n",
            "FILTER MODEL EPOCH  3\n",
            "FILTER MODEL EPOCH  4\n",
            "FILTER MODEL EPOCH  5\n",
            "FILTER MODEL EPOCH  6\n",
            "FILTER MODEL EPOCH  7\n",
            "FILTER MODEL EPOCH  8\n",
            "FILTER MODEL EPOCH  9\n",
            "FILTER MODEL EPOCH  10\n",
            "FILTER MODEL EPOCH  11\n",
            "FILTER MODEL EPOCH  12\n",
            "FILTER MODEL EPOCH  13\n",
            "FILTER MODEL EPOCH  14\n",
            "FILTER MODEL EPOCH  15\n",
            "FILTER MODEL EPOCH  16\n",
            "FILTER MODEL EPOCH  17\n",
            "FILTER MODEL EPOCH  18\n",
            "FILTER MODEL EPOCH  19\n",
            "FILTER MODEL EPOCH  20\n",
            "FILTER MODEL EPOCH  21\n",
            "FILTER MODEL EPOCH  22\n",
            "FILTER MODEL EPOCH  23\n",
            "FILTER MODEL EPOCH  24\n",
            "Train F1 Score:  (0.6666666666666666, 0.5, 0.5714285714285715)\n",
            "Test F1 Score:  (1.0, 0.25, 0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlua00wK1BVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "4a70496f-dd8f-43e6-b01f-9facca41222a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from preprocess import get_data\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--mode', type=str, default='test',\n",
        "                    help='Can be \"train\" or \"test\"')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "class ECModel(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    This model classifies input clauses as cause clauses,\n",
        "    emotion clauses, or neither.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, clause_size):\n",
        "        super(ECModel, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.clause_size = clause_size\n",
        "        self.embedding_size = 200\n",
        "        self.batch_size = 1\n",
        "        self.rnn_size = 100\n",
        "        self.num_classes = 1\n",
        "        self.hidden_layer_size = 100\n",
        "\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "        self.lower_model = tf.keras.Sequential()\n",
        "        self.lower_model.add(tf.keras.layers.Embedding(vocab_size, self.embedding_size, input_length=clause_size))\n",
        "\n",
        "        self.attention = tf.keras.layers.Attention()\n",
        "\n",
        "        self.emotion_model = tf.keras.Sequential()\n",
        "        self.emotion_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.rnn_size)))\n",
        "        self.emotion_model.add(tf.keras.layers.Flatten())\n",
        "        self.emotion_model.add(tf.keras.layers.Dense(self.hidden_layer_size, activation='relu'))\n",
        "        self.emotion_model.add(tf.keras.layers.Dense(self.num_classes, activation='sigmoid'))\n",
        "\n",
        "        self.cause_model = tf.keras.Sequential()\n",
        "        self.cause_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.rnn_size)))\n",
        "        self.cause_model.add(tf.keras.layers.Flatten())\n",
        "        self.cause_model.add(tf.keras.layers.Dense(self.hidden_layer_size, activation='relu'))\n",
        "        self.cause_model.add(tf.keras.layers.Dense(self.num_classes, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    def call(self, clauses):\n",
        "        \"\"\"\n",
        "        Calls the model on the input clauses.\n",
        "        \"\"\"\n",
        "        lower_output = self.lower_model(clauses)\n",
        "        lower_output = self.attention([lower_output, lower_output, lower_output])\n",
        "\n",
        "        emotion_probs = self.emotion_model(lower_output)\n",
        "        cause_probs = self.cause_model(lower_output)\n",
        "\n",
        "        return emotion_probs, cause_probs\n",
        "\n",
        "    def get_embeddings(self, clauses):\n",
        "        \"\"\"\n",
        "        Get the representation of the clauses from the lower-level model.\n",
        "        \"\"\"\n",
        "        return self.lower_model(clauses)\n",
        "\n",
        "    def get_likely_clauses(self, clauses, probs):\n",
        "        \"\"\"\n",
        "        Get the clauses that are labeled as 1.\n",
        "        \"\"\"\n",
        "        labels = np.squeeze(get_labels(probs))\n",
        "        likely_indices = np.squeeze(np.argwhere(labels))\n",
        "        return clauses[likely_indices].reshape((-1, self.clause_size))\n",
        "\n",
        "    def loss(self, cause_probabilities, cause_labels, emotion_probabilities, emotion_labels, alpha=0.5):\n",
        "        \"\"\"\n",
        "        Calculates loss as a weighted sum of the losses for cause classification and emotion classification.\n",
        "        \"\"\"\n",
        "        cause_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(cause_labels, cause_probabilities))\n",
        "        emotion_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(emotion_labels, emotion_probabilities))\n",
        "        return alpha*emotion_loss + (1 - alpha)*cause_loss\n",
        "\n",
        "    def train(self, train_clauses, train_cause_labels, train_emotion_labels):\n",
        "        \"\"\"\n",
        "        Trains the model.\n",
        "        \"\"\"\n",
        "        num_examples = train_clauses.shape[0]\n",
        "\n",
        "        start_index = 0\n",
        "        end_index = start_index + self.batch_size\n",
        "\n",
        "        while (end_index <= num_examples):\n",
        "            batch_clauses = train_clauses[start_index:end_index]\n",
        "            batch_cause_labels = train_cause_labels[start_index:end_index]\n",
        "            batch_emotion_labels = train_emotion_labels[start_index:end_index]\n",
        "\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                emotion_probabilities, cause_probabilities = self.call(batch_clauses)\n",
        "                loss = self.loss(cause_probabilities, batch_cause_labels, emotion_probabilities, batch_emotion_labels, 0.5)\n",
        "                # print(\"EC MODEL TRAIN LOSS: \", loss)\n",
        "\n",
        "            emotion_trainable_variables = self.lower_model.trainable_variables + self.attention.trainable_variables + self.emotion_model.trainable_variables\n",
        "            cause_trainable_variables = self.lower_model.trainable_variables + self.attention.trainable_variables + self.cause_model.trainable_variables\n",
        "\n",
        "            emotion_gradients = tape.gradient(loss, emotion_trainable_variables)\n",
        "            cause_gradients = tape.gradient(loss, cause_trainable_variables)\n",
        "\n",
        "            self.optimizer.apply_gradients(zip(emotion_gradients, emotion_trainable_variables))\n",
        "            self.optimizer.apply_gradients(zip(cause_gradients, cause_trainable_variables))\n",
        "\n",
        "            start_index = end_index\n",
        "            end_index = start_index + self.batch_size\n",
        "\n",
        "    def test(self, test_clauses, test_cause_labels, test_emotion_labels):\n",
        "        \"\"\"\n",
        "        Tests the model. Returns the mean loss from the test data.\n",
        "        \"\"\"\n",
        "        num_examples = test_clauses.shape[0]\n",
        "\n",
        "        start_index = 0\n",
        "        end_index = start_index + self.batch_size\n",
        "\n",
        "        loss = []\n",
        "        while (end_index <= num_examples):\n",
        "            batch_clauses = test_clauses[start_index:end_index]\n",
        "            batch_cause_labels = test_cause_labels[start_index:end_index]\n",
        "            batch_emotion_labels = test_emotion_labels[start_index:end_index]\n",
        "\n",
        "            cause_probabilities, emotion_probabilities = self.call(batch_clauses)\n",
        "            loss.append(self.loss(cause_probabilities, batch_cause_labels, emotion_probabilities, batch_emotion_labels, 0.5))\n",
        "\n",
        "            start_index = end_index\n",
        "            end_index = start_index + self.batch_size\n",
        "\n",
        "        return np.mean(loss)\n",
        "\n",
        "\n",
        "class FilterModel(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    This model is a logistic regression model that filters emotion-cause pairs to obtain the valid pairs in which the cause\n",
        "    clauses correspond to the emotion clauses.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(FilterModel, self).__init__()\n",
        "        self.batch_size = 1\n",
        "        self.hidden_layer_size = 100\n",
        "        self.dense_1 = tf.keras.layers.Dense(self.hidden_layer_size, activation=\"relu\")\n",
        "        self.dense_2 = tf.keras.layers.Dense(self.hidden_layer_size, activation=\"relu\")\n",
        "        self.dense_3 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Calls the model on the input pairs.\n",
        "        \"\"\"\n",
        "        return self.dense_3(self.dense_2(self.dense_1(inputs)))\n",
        "\n",
        "    def loss(self, labels, pred):\n",
        "        \"\"\"\n",
        "        Calculates the binary cross entropy loss for valid pair classification.\n",
        "        \"\"\"\n",
        "        return tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels, pred))\n",
        "\n",
        "    def train(self, train_inputs, train_labels):\n",
        "        \"\"\"\n",
        "        Train the model for the given input pairs, and binary labels (1 if the pair is valid, 0 otherwise).\n",
        "        \"\"\"\n",
        "        current_start = 0\n",
        "        num_samples = train_inputs.shape[0]\n",
        "        while current_start + self.batch_size <= num_samples:\n",
        "            current_batch = train_inputs[current_start:current_start + self.batch_size]\n",
        "            current_labels = train_labels[current_start:current_start + self.batch_size]\n",
        "\n",
        "            with tf.GradientTape() as t:\n",
        "                batch_pred = self.call(current_batch)\n",
        "                batch_loss = self.loss(current_labels, batch_pred)\n",
        "                # print(\"Filter Model Train Loss: \", batch_loss)\n",
        "            gradients = t.gradient(batch_loss, self.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "            current_start += self.batch_size\n",
        "\n",
        "    def get_cartesian_products(self, embedding_model, emotion_clauses, cause_clauses, real_pairs):\n",
        "        \"\"\"\n",
        "        Given the set of emotion clauses and the set of cause clauses, obtain the embeddings from the embedding model\n",
        "        Then produce the Cartesian product of both the clauses and their embeddings.\n",
        "        \"\"\"\n",
        "        emotion_embeddings = embedding_model.get_embeddings(emotion_clauses).numpy()\n",
        "        emotion_embeddings = emotion_embeddings.reshape((emotion_embeddings.shape[0], -1))\n",
        "        cause_embeddings = embedding_model.get_embeddings(cause_clauses).numpy()\n",
        "        cause_embeddings = cause_embeddings.reshape((cause_embeddings.shape[0], -1))\n",
        "        if cause_embeddings.shape[0] == 0 or emotion_embeddings.shape[0] == 0:\n",
        "            return np.array([]), np.array([])\n",
        "        embedding_pairs = np.array([[np.append(e, c) for c in cause_embeddings] for e in emotion_embeddings])\n",
        "        label_pairs = np.array([[self.is_real_pair(e, c, real_pairs) for c in cause_clauses] for e in emotion_clauses])\n",
        "        embedding_pairs = embedding_pairs.reshape((-1, embedding_pairs.shape[-1]))\n",
        "        label_pairs = label_pairs.reshape((-1))\n",
        "\n",
        "        return embedding_pairs, label_pairs\n",
        "\n",
        "    def is_real_pair(self, emotion_clause, cause_clause, real_pairs):\n",
        "        \"\"\"\n",
        "        Returns a Boolean representing whether or not the given emotion-cause pair\n",
        "        is in the list of real emotion-cause pairs.\n",
        "        \"\"\"\n",
        "        for i in range(len(real_pairs)):\n",
        "            if np.all(real_pairs[i] == [emotion_clause, cause_clause]):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "def get_labels(probs):\n",
        "    \"\"\"\n",
        "    Get the binary labels for inputs given probabilities. Samples a label (0/1)\n",
        "    based on the probability for each label, as computed by the model.\n",
        "    \"\"\"\n",
        "    data = probs.numpy()\n",
        "    labels = np.zeros(data.shape)\n",
        "    for i in range(labels.shape[0]):\n",
        "        for j in range(labels.shape[1]):\n",
        "            labels[i][j] = np.random.choice(2, 1, p=[1-data[i][j], data[i][j]])\n",
        "    return labels\n",
        "\n",
        "def scores(labels, pred):\n",
        "    \"\"\"\n",
        "    Calculates the precision, recall, and F1 scores.\n",
        "\n",
        "    :param labels: 1D np.array of actual labels.\n",
        "    :param pred: 1D np.array of predicted labels.\n",
        "    :return tuple of precision, recall, and F1 scores.\n",
        "    \"\"\"\n",
        "    true_positive = np.sum(np.logical_and((labels==1), (pred==1)))\n",
        "    true_negative = np.sum(np.logical_and((labels==0), (pred==0)))\n",
        "    false_positive = np.sum(np.logical_and((labels==0), (pred==1)))\n",
        "    false_negative = np.sum(np.logical_and((labels==1), (pred==0)))\n",
        "\n",
        "    # Precision represents the correct percentage of all positive predicitions\n",
        "    precision = true_positive / (true_positive + false_positive)\n",
        "    # Recall represents how well we can predict results that should be positive\n",
        "    recall = true_positive / (true_positive + false_negative)\n",
        "\n",
        "    # F1 is the harmonic mean of precision and recall\n",
        "    # intuitively, it represents the quality of how well we should trust a prediction that's positive\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def main():\n",
        "    # Obtain preprocessed data.\n",
        "    train_clauses, test_clauses, train_emotion_labels, test_emotion_labels, \\\n",
        "    train_cause_labels, test_cause_labels, train_emotion_cause_pairs, \\\n",
        "    test_emotion_cause_pairs, word2id, pad_index, clause_size = get_data(\"data.txt\")\n",
        "\n",
        "    ec_extract_model = ECModel(len(word2id), clause_size)\n",
        "\n",
        "    # Train ECModel.\n",
        "    num_epochs = 5\n",
        "\n",
        "    # For saving/loading models.\n",
        "    checkpoint_dir = './checkpoints'\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(ec_extract_model=ec_extract_model)\n",
        "    manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\n",
        "\n",
        "    checkpoint.restore(manager.latest_checkpoint)\n",
        "\n",
        "    if args.mode == \"train\":\n",
        "        for e in range(num_epochs):\n",
        "            print(\"EC MODEL EPOCH: \", e)\n",
        "            ec_extract_model.train(train_clauses, train_cause_labels, train_emotion_labels)\n",
        "        manager.save()\n",
        "\n",
        "    # Test ECModel.\n",
        "    num_examples = 30\n",
        "    train_clauses = train_clauses[:num_examples]\n",
        "    test_clauses = test_clauses[:num_examples]\n",
        "    train_emotion_probs, train_cause_probs = ec_extract_model.call(train_clauses)\n",
        "    test_emotion_probs, test_cause_probs = ec_extract_model.call(test_clauses)\n",
        "\n",
        "    # Extract emotion and cause clauses.\n",
        "    train_emotion_clauses = ec_extract_model.get_likely_clauses(train_clauses, train_emotion_probs)\n",
        "    train_cause_clauses = ec_extract_model.get_likely_clauses(train_clauses, train_cause_probs)\n",
        "\n",
        "    print(\"NUMBER OF TRAIN CLAUSES: \", train_clauses.shape)\n",
        "    print(\"NUMBER OF EXTRACTED TRAIN EMOTION CLAUSES: \", train_emotion_clauses.shape)\n",
        "    print(\"NUMBER OF EXTRACTED TRAIN CAUSE CLAUSES: \", train_cause_clauses.shape)\n",
        "\n",
        "    test_emotion_clauses = ec_extract_model.get_likely_clauses(test_clauses, test_emotion_probs)\n",
        "    test_cause_clauses = ec_extract_model.get_likely_clauses(test_clauses, test_cause_probs)\n",
        "\n",
        "    print(\"NUMBER OF TEST CLAUSES: \", test_clauses.shape)\n",
        "    print(\"NUMBER OF EXTRACTED TEST EMOTION CLAUSES: \", test_emotion_clauses.shape)\n",
        "    print(\"NUMBER OF EXTRACTED TEST CAUSE CLAUSES: \", test_cause_clauses.shape)\n",
        "\n",
        "    # Create filter model.\n",
        "    pair_filter_model = FilterModel()\n",
        "\n",
        "    # Apply Cartesian product to set of emotion clauses and set of cause clauses to obtain all possible pairs.\n",
        "    train_embedding_pairs, train_label_pairs = pair_filter_model.get_cartesian_products(ec_extract_model, train_emotion_clauses, train_cause_clauses, train_emotion_cause_pairs)\n",
        "    test_embedding_pairs, test_label_pairs = pair_filter_model.get_cartesian_products(ec_extract_model, test_emotion_clauses, test_cause_clauses, test_emotion_cause_pairs)\n",
        "\n",
        "    # Train filter model.\n",
        "    num_epochs = 25\n",
        "    for e in range(num_epochs):\n",
        "        print(\"FILTER MODEL EPOCH \", e)\n",
        "        pair_filter_model.train(train_embedding_pairs, train_label_pairs)\n",
        "\n",
        "    # Test filter model.\n",
        "    train_pair_probs = pair_filter_model.call(train_embedding_pairs)\n",
        "    train_predicted_label_pairs = np.squeeze(get_labels(train_pair_probs))\n",
        "\n",
        "    test_pair_probs = pair_filter_model.call(test_embedding_pairs)\n",
        "    test_predicted_label_pairs = np.squeeze(get_labels(test_pair_probs))\n",
        "\n",
        "    # Calculate F1 Score.\n",
        "    train_f1_score = scores(train_label_pairs, train_predicted_label_pairs)\n",
        "    print(\"Train F1 Score: \", train_f1_score)\n",
        "\n",
        "    test_f1_score = scores(test_label_pairs, test_predicted_label_pairs)\n",
        "    print(\"Test F1 Score: \", test_f1_score)\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUMBER OF TRAIN CLAUSES:  (30, 26)\n",
            "NUMBER OF EXTRACTED TRAIN EMOTION CLAUSES:  (19, 26)\n",
            "NUMBER OF EXTRACTED TRAIN CAUSE CLAUSES:  (13, 26)\n",
            "NUMBER OF TEST CLAUSES:  (30, 26)\n",
            "NUMBER OF EXTRACTED TEST EMOTION CLAUSES:  (16, 26)\n",
            "NUMBER OF EXTRACTED TEST CAUSE CLAUSES:  (12, 26)\n",
            "FILTER MODEL EPOCH  0\n",
            "FILTER MODEL EPOCH  1\n",
            "FILTER MODEL EPOCH  2\n",
            "FILTER MODEL EPOCH  3\n",
            "FILTER MODEL EPOCH  4\n",
            "FILTER MODEL EPOCH  5\n",
            "FILTER MODEL EPOCH  6\n",
            "FILTER MODEL EPOCH  7\n",
            "FILTER MODEL EPOCH  8\n",
            "FILTER MODEL EPOCH  9\n",
            "FILTER MODEL EPOCH  10\n",
            "FILTER MODEL EPOCH  11\n",
            "FILTER MODEL EPOCH  12\n",
            "FILTER MODEL EPOCH  13\n",
            "FILTER MODEL EPOCH  14\n",
            "FILTER MODEL EPOCH  15\n",
            "FILTER MODEL EPOCH  16\n",
            "FILTER MODEL EPOCH  17\n",
            "FILTER MODEL EPOCH  18\n",
            "FILTER MODEL EPOCH  19\n",
            "FILTER MODEL EPOCH  20\n",
            "FILTER MODEL EPOCH  21\n",
            "FILTER MODEL EPOCH  22\n",
            "FILTER MODEL EPOCH  23\n",
            "FILTER MODEL EPOCH  24\n",
            "Train F1 Score:  (1.0, 0.3333333333333333, 0.5)\n",
            "Test F1 Score:  (nan, 0.0, nan)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:235: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7de_Ok4C4Pwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}